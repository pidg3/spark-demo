{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba45dfaa-25f5-4c49-b77c-a564dec63735",
   "metadata": {},
   "source": [
    "# Wikipedia definition\n",
    "\n",
    "Apache Spark is an open-source unified analytics engine for large-scale data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a908c0-3646-48b7-9ac2-8d6d65fa2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, split, collect_list, rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94ab7508-b919-4571-9d98-0f96575a8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------+--------------------+\n",
      "| id|   name|age| department|              skills|\n",
      "+---+-------+---+-----------+--------------------+\n",
      "|  1|  Alice| 30|Engineering|     Python,Java,SQL|\n",
      "|  2|    Bob| 25|      Sales|Communication,Neg...|\n",
      "|  3|Charlie| 40|  Marketing|SEO,Content Marke...|\n",
      "|  4|  David| 28|Engineering|        Java,C++,AWS|\n",
      "|  5|    Eve| 35|      Sales|CRM,Salesforce,Le...|\n",
      "+---+-------+---+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"DockerizedDBDemo\").getOrCreate()\n",
    "\n",
    "# PostgreSQL connection details\n",
    "db_url = \"jdbc:postgresql://postgres:5432/mydatabase\"\n",
    "db_properties = {\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Read data from PostgreSQL\n",
    "employees_df = spark.read.jdbc(url=db_url, table=\"employees\", properties=db_properties)\n",
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b34312e-46b7-477f-9bb6-35e733801483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|   name|            skill|\n",
      "+-------+-----------------+\n",
      "|  Alice|           Python|\n",
      "|  Alice|             Java|\n",
      "|  Alice|              SQL|\n",
      "|    Bob|    Communication|\n",
      "|    Bob|      Negotiation|\n",
      "|Charlie|              SEO|\n",
      "|Charlie|Content Marketing|\n",
      "|Charlie|     Social Media|\n",
      "|  David|             Java|\n",
      "|  David|              C++|\n",
      "|  David|              AWS|\n",
      "|    Eve|              CRM|\n",
      "|    Eve|       Salesforce|\n",
      "|    Eve|  Lead Generation|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-----------------+-----+\n",
      "|            skill|count|\n",
      "+-----------------+-----+\n",
      "|             Java|    2|\n",
      "|              SEO|    1|\n",
      "|              AWS|    1|\n",
      "|              C++|    1|\n",
      "|       Salesforce|    1|\n",
      "|     Social Media|    1|\n",
      "|  Lead Generation|    1|\n",
      "|              SQL|    1|\n",
      "|           Python|    1|\n",
      "|    Communication|    1|\n",
      "|Content Marketing|    1|\n",
      "|              CRM|    1|\n",
      "|      Negotiation|    1|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Explode and analyze skills data\n",
    "\n",
    "# Assume a new 'skills' column with comma-separated values\n",
    "split_employees_df = employees_df.withColumn(\"skills\", split(col(\"skills\"), \",\"))\n",
    "\n",
    "# Explode the skills array into individual rows\n",
    "exploded_employees_df = split_employees_df.select(col(\"name\"), explode(col(\"skills\")).alias(\"skill\"))\n",
    "exploded_employees_df.show()\n",
    "\n",
    "# Count the occurrences of each skill\n",
    "skill_counts = exploded_employees_df.groupBy(\"skill\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "skill_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f71e0ae-2f7a-4da0-b639-3bea73f355d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------+--------------------+------------+\n",
      "| id|   name|age| department|              skills|rank_in_dept|\n",
      "+---+-------+---+-----------+--------------------+------------+\n",
      "|  1|  Alice| 30|Engineering|     Python,Java,SQL|           1|\n",
      "|  4|  David| 28|Engineering|        Java,C++,AWS|           2|\n",
      "|  3|Charlie| 40|  Marketing|SEO,Content Marke...|           1|\n",
      "|  5|    Eve| 35|      Sales|CRM,Salesforce,Le...|           1|\n",
      "|  2|    Bob| 25|      Sales|Communication,Neg...|           2|\n",
      "+---+-------+---+-----------+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Window function to rank employees within departments\n",
    "\n",
    "# Define a window specification partitioned by department and ordered by age\n",
    "window_spec = Window.partitionBy(\"department\").orderBy(col(\"age\").desc())\n",
    "\n",
    "# Add a rank column based on age within each department\n",
    "ranked_df = employees_df.withColumn(\"rank_in_dept\", rank().over(window_spec))\n",
    "\n",
    "ranked_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b901668e-9ef3-4cb3-a2c4-a1adb8a79ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+-----------+--------------------+----------------+\n",
      "| id|   name|age| department|              skills|pension_category|\n",
      "+---+-------+---+-----------+--------------------+----------------+\n",
      "|  1|  Alice| 30|Engineering|     Python,Java,SQL|       MidCareer|\n",
      "|  2|    Bob| 25|      Sales|Communication,Neg...|      NewJoiners|\n",
      "|  3|Charlie| 40|  Marketing|SEO,Content Marke...|       MidCareer|\n",
      "|  4|  David| 28|Engineering|        Java,C++,AWS|      NewJoiners|\n",
      "|  5|    Eve| 35|      Sales|CRM,Salesforce,Le...|       MidCareer|\n",
      "+---+-------+---+-----------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. User-defined function (UDF) to categorize employees\n",
    "\n",
    "# Define a UDF to categorize employees based on age\n",
    "def categorize_pension_messaging(age):\n",
    "    if age < 30:\n",
    "        return \"NewJoiners\"\n",
    "    elif age < 50:\n",
    "        return \"MidCareer\"\n",
    "    else:\n",
    "        return \"LateCareer\"\n",
    "\n",
    "# Register the UDF\n",
    "categorize_age_udf = spark.udf.register(\"categorize_pension_messaging\", categorize_pension_messaging)\n",
    "\n",
    "# Apply the UDF to create a new 'age_category' column\n",
    "categorized_df = employees_df.withColumn(\"pension_category\", categorize_age_udf(col(\"age\")))\n",
    "\n",
    "categorized_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a44589-7eee-4176-95e8-d505b13e073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84386fe-ec04-492e-8a09-183a5368f1b5",
   "metadata": {},
   "source": [
    "# Key takeaways on Spark\n",
    "\n",
    "- Offers a series of utility methods for working with data. (Obvious Hyble use case - parsing out helpful data from the order JSON). \n",
    "- Can be used for any stage of ETL pipelines.\n",
    "- Optimised to run in a distributed cluster, doing as much processing in-memory as possible. Therefore fast and scalable.\n",
    "- Generally a bit easier to get started with than Hadoop/MapReduce."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
